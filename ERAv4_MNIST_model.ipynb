{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c56f712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd117530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aeb0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "batch_size = 64\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.RandomRotation(15),\n",
    "                        transforms.RandomAffine(degrees=0, translate=(0.15, 0.15)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.131,), (0.308,)) # mean 0.13101533792088266\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.131,), (0.308,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "477e6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot accuracy and loss graphs\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train_batch_losses = []\n",
    "train_batch_acc = []\n",
    "test_batch_losses = []\n",
    "test_batch_acc = []\n",
    "\n",
    "def GetCorrectPredCount(pPrediction, pLabels):\n",
    "  return pPrediction.argmax(dim=1).eq(pLabels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b375c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = criterion(output, target)\n",
    "        train_loss+=loss.item()\n",
    "        train_batch_losses.append(loss.item()) # Store batch loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += GetCorrectPredCount(output, target)\n",
    "        processed += len(data)\n",
    "        Accuracy = float(100*correct/processed)\n",
    "        #pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx} Accuracy={Accuracy}')\n",
    "        train_batch_acc.append(Accuracy) # Store batch accuracy\n",
    "        pbar.set_description(desc= f'loss={train_loss/len(train_loader)} batch_id={batch_idx} Accuracy={Accuracy}')\n",
    "    train_acc.append(Accuracy)\n",
    "    train_losses.append(train_loss/len(train_loader))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            #test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            loss = criterion(output, target).item()\n",
    "            test_loss += loss\n",
    "            test_batch_losses.append(loss)\n",
    "            #pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            #correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            correct += GetCorrectPredCount(output, target)\n",
    "            test_batch_acc.append(100. * correct / len(test_loader.dataset)) # Store batch accuracy\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
    "    test_losses.append(test_loss)\n",
    "    Accuracy = float(float(100. * correct) / len(test_loader.dataset))\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.2f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cf6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Conv2d(8, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Conv2d(32, 40, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(40, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ab6f7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              72\n",
      "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
      "              ReLU-3            [-1, 8, 28, 28]               0\n",
      "            Conv2d-4           [-1, 16, 28, 28]           1,152\n",
      "       BatchNorm2d-5           [-1, 16, 28, 28]              32\n",
      "              ReLU-6           [-1, 16, 28, 28]               0\n",
      "         MaxPool2d-7           [-1, 16, 14, 14]               0\n",
      "            Conv2d-8           [-1, 32, 14, 14]           4,608\n",
      "       BatchNorm2d-9           [-1, 32, 14, 14]              64\n",
      "             ReLU-10           [-1, 32, 14, 14]               0\n",
      "           Conv2d-11           [-1, 40, 14, 14]          11,520\n",
      "      BatchNorm2d-12           [-1, 40, 14, 14]              80\n",
      "             ReLU-13           [-1, 40, 14, 14]               0\n",
      "        MaxPool2d-14             [-1, 40, 7, 7]               0\n",
      "AdaptiveAvgPool2d-15             [-1, 40, 1, 1]               0\n",
      "           Linear-16                   [-1, 10]             410\n",
      "================================================================\n",
      "Total params: 17,954\n",
      "Trainable params: 17,954\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.79\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 0.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947fc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': 10,\n",
       " 'gamma': 0.2,\n",
       " 'base_lrs': [0.001],\n",
       " 'last_epoch': 0,\n",
       " '_step_count': 1,\n",
       " '_is_initial': False,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [0.001]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)\n",
    "scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04c505ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.8898803702990215 batch_id=1874 Accuracy=90.16833333333334: 100%|██████████| 1875/1875 [02:36<00:00, 11.97it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9742/10000 (97.42%)\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.6469080656051636 batch_id=1874 Accuracy=97.35666666666667: 100%|██████████| 1875/1875 [02:37<00:00, 11.91it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9860/10000 (98.60%)\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.624958935546875 batch_id=1874 Accuracy=97.77333333333333: 100%|██████████| 1875/1875 [02:35<00:00, 12.04it/s]  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9844/10000 (98.44%)\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.6120004649480184 batch_id=1874 Accuracy=98.06833333333333: 100%|██████████| 1875/1875 [02:56<00:00, 10.60it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9792/10000 (97.92%)\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.6041604083061218 batch_id=1874 Accuracy=98.235: 100%|██████████| 1875/1875 [02:35<00:00, 12.05it/s]            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5978048844973246 batch_id=1874 Accuracy=98.38666666666667: 100%|██████████| 1875/1875 [02:41<00:00, 11.60it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5932514966011048 batch_id=1874 Accuracy=98.48166666666667: 100%|██████████| 1875/1875 [04:19<00:00,  7.22it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5903639246622722 batch_id=1874 Accuracy=98.53333333333333: 100%|██████████| 1875/1875 [04:11<00:00,  7.46it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5871141179402669 batch_id=1874 Accuracy=98.635: 100%|██████████| 1875/1875 [04:33<00:00,  6.86it/s]             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5845553020795187 batch_id=1874 Accuracy=98.66666666666667: 100%|██████████| 1875/1875 [04:01<00:00,  7.78it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5746332131067912 batch_id=1874 Accuracy=98.87: 100%|██████████| 1875/1875 [04:37<00:00,  6.76it/s]             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9936/10000 (99.36%)\n",
      "\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5736182805061341 batch_id=1874 Accuracy=98.885: 100%|██████████| 1875/1875 [03:49<00:00,  8.18it/s]            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9933/10000 (99.33%)\n",
      "\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5718430232683818 batch_id=1874 Accuracy=98.935: 100%|██████████| 1875/1875 [03:57<00:00,  7.90it/s]            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9932/10000 (99.32%)\n",
      "\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5717437333106995 batch_id=1874 Accuracy=98.91: 100%|██████████| 1875/1875 [03:51<00:00,  8.09it/s]             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9935/10000 (99.35%)\n",
      "\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5712053905169169 batch_id=1874 Accuracy=98.955: 100%|██████████| 1875/1875 [02:53<00:00, 10.78it/s]            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9937/10000 (99.37%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print(f'Epoch {epoch}')\n",
    "    train(model, device, train_loader, optimizer, criterion)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f635d9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.570358858648936 batch_id=1874 Accuracy=98.96: 100%|██████████| 1875/1875 [03:07<00:00,  9.98it/s]              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9932/10000 (99.32%)\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5701137790044148 batch_id=1874 Accuracy=98.965: 100%|██████████| 1875/1875 [03:57<00:00,  7.90it/s]            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9934/10000 (99.34%)\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5691603439966838 batch_id=1874 Accuracy=98.95666666666666: 100%|██████████| 1875/1875 [04:43<00:00,  6.61it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9935/10000 (99.35%)\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.5691644907633464 batch_id=1874 Accuracy=98.945: 100%|██████████| 1875/1875 [04:30<00:00,  6.93it/s]            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9930/10000 (99.30%)\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.568643266805013 batch_id=1874 Accuracy=98.985: 100%|██████████| 1875/1875 [04:05<00:00,  7.64it/s]             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.02, Accuracy: 9941/10000 (99.41%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print(f'Epoch {epoch}')\n",
    "    train(model, device, train_loader, optimizer, criterion)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ERAv4_MNIST_model_S5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
